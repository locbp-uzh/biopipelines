"""
This pipeline shows how improve the difference in predicted binding affinity between open and close form of a carbocyanine 7 chloride and halotag7 starting from a Boltz model of the open form.
We further introduce:
1. Filtering based on the distance between the end cap of the carbocyanine (specifically its nitrogen atom) and the aspartate, to avoid cases in which both the dye and the linker are within the pocket. 
One can open the original pdb file with pymol and click on the atom of interest in atom mode, to see the atom name:
Example: You clicked /1_best//B/LIG`1/N88 -> (pk1)
2. Treatment of two enantiomers and composition of sequences from mutation profile of both
"""

#!/usr/bin/env python3
import os, sys
sys.path.insert(0, os.getcwd()) #to see scripts in current folder

from PipelineScripts.pipeline import Pipeline
from PipelineScripts.load_output import LoadOutput
from PipelineScripts.ligand_mpnn import LigandMPNN
from PipelineScripts.mutation_profiler import MutationProfiler
from PipelineScripts.mutation_composer import MutationComposer
from PipelineScripts.boltz2 import Boltz2
from PipelineScripts.residue_atom_distance import ResidueAtomDistance
from PipelineScripts.merge_datasheets import MergeDatasheets
from PipelineScripts.concatenate_datasheets import ConcatenateDatasheets
from PipelineScripts.remove_duplicates import RemoveDuplicates
from PipelineScripts.filter import Filter
from PipelineScripts.select_best import SelectBest

pipeline = Pipeline(
    pipeline_name="LigandMPNN-MutationComposer-Cycle", #Will create a folder in /shares/USER/<pipeline_name>
    job_name="HT7_Cy7_C_enantiomers_single_point", #Unique job folder in /shares/USER/<pipeline_name>/job_name_NNN
    job_description="Profiling of mutations occuring over 1000 sequences generated by LigandMPNN and composition of sequences based on it, cycling to improve difference in affinity between open and bound")

pipeline.resources(
    gpu="A100",
    time="24:00:00",
    memory="16GB"
)

"""
We load both open and close form so that we calculate the delta in affinity and use it as benchmark
"""
best_R = pipeline.add(LoadOutput('/shares/locbp.chem.uzh/gquarg/BioPipelines/Boltz/HT7_Cy7_C_R_001/ToolOutputs/1_Boltz2_output.json'))
best_RR = pipeline.add(LoadOutput('/shares/locbp.chem.uzh/gquarg/BioPipelines/Boltz/HT7_Cy7_C_RR_001/ToolOutputs/1_Boltz2_output.json'))
best_S = pipeline.add(LoadOutput('/shares/locbp.chem.uzh/gquarg/BioPipelines/Boltz/HT7_Cy7_C_S_001/ToolOutputs/1_Boltz2_output.json'))
best_SS = pipeline.add(LoadOutput('/shares/locbp.chem.uzh/gquarg/BioPipelines/Boltz/HT7_Cy7_C_SS_001/ToolOutputs/1_Boltz2_output.json'))

original_analysis = pipeline.add(MergeDatasheets(
    datasheets=[best_R.output.datasheets.affinity,
               best_RR.output.datasheets.affinity,
               best_S.output.datasheets.affinity,
               best_SS.output.datasheets.affinity],
    prefixes=["R_", "RR_","S_","SS_"],
    id_map={"original":["HT7_Cy7_C_R","HT7_Cy7_C_RR","HT7_Cy7_C_S","HT7_Cy7_C_SS"]},
    calculate={"affinity_delta_R": "R_affinity_pred_value - RR_affinity_pred_value",
               "affinity_delta_S": "S_affinity_pred_value - SS_affinity_pred_value",
               "affinity_delta": "R_affinity_pred_value - RR_affinity_pred_value + S_affinity_pred_value - SS_affinity_pred_value"}
))

NUM_CYCLES = 20
all_sequences_seen = None  # Track all sequences across cycles

# Track all analyses and pools across cycles for SelectBest
all_analyses = [original_analysis]  # Start with original baseline
all_pools = [{"R":best_R,"S":best_S}]  # Start with original best structure
all_open_best = [{"R":best_R,"S":best_S}] #will be used to plot the cycle-evolution 

for CYCLE in range(NUM_CYCLES):
    pipeline.set_suffix(f"Cycle{CYCLE}")
    """
    Diversify with LigandMPNN
    """
    mutation_range = "141+143+145+147-149+151-152+154+157+160-161+165+167-168+170-172+175-176+178+180+245+271"
    lmpnn_R = pipeline.add(LigandMPNN(structures=best_R.output, #this is equivalent to boltz2.output
                                    ligand="LIG", #in ligand mpnn you should always specify the ligand name, which is LIG if from Boltz
                                    num_sequences=1000,
                                    batch_size=25, 
                                    redesigned=mutation_range, 
                                    design_within=4))
    lmpnn_S = pipeline.add(LigandMPNN(structures=best_S.output, #this is equivalent to boltz2.output
                                    ligand="LIG", #in ligand mpnn you should always specify the ligand name, which is LIG if from Boltz
                                    num_sequences=1000,
                                    batch_size=25, 
                                    redesigned=mutation_range,
                                    design_within=4))
    
    profiler_R = pipeline.add(MutationProfiler(original=best_R.output,
                                             mutants=lmpnn_R.output))
    profiler_S = pipeline.add(MutationProfiler(original=best_S.output,
                                             mutants=lmpnn_S.output))
    composer = pipeline.add(MutationComposer(frequencies=[profiler_R.output.datasheets.absolute_frequencies,
                                                          profiler_S.output.datasheets.absolute_frequencies],
                                             num_sequences=12,
                                             mode="weighted_random",
                                             combination_strategy="stack", #take one mutation from R one from S together
                                             prefix=f"HT_C{CYCLE+1}"))
    
    """
    Filter NEW sequences only (remove duplicates against historical)
    """
    unique_new_sequences = pipeline.add(RemoveDuplicates(
        pool=composer.output,           # Current cycle sequences  
        history=all_sequences_seen.output if all_sequences_seen else None,  # History from previous cycles (None for first cycle)
        compare="sequence"           # Compare protein sequences
    ))
    
    """
    Update history with unique sequences AFTER deduplication
    """
    if all_sequences_seen is None:
        # First cycle - initialize history with ConcatenateDatasheets (single input)
        all_sequences_seen = pipeline.add(ConcatenateDatasheets(
            datasheets=[unique_new_sequences.output.datasheets.sequences]
        ))
    else:
        # Subsequent cycles - concatenate unique sequences with existing history
        all_sequences_seen = pipeline.add(ConcatenateDatasheets(
            datasheets=[unique_new_sequences.output.datasheets.sequences, 
                       all_sequences_seen.output.datasheets.concatenated]
        ))
    
    """
    Fold only the NEW unique structures
    SMILES canonicized @ https://www.leskoff.com/s01812-0
    """
    boltz_apo = pipeline.add(Boltz2(proteins=unique_new_sequences.output))
    boltz_holo_R = pipeline.add(Boltz2(proteins=unique_new_sequences.output,
                                    ligands=r"CC/1(C)C2=C(C=CC=C2)N(C)\C1=C\C=C\C=C\C=C\C3=[N+](C)C4=C(C=CC=C4)[C@@]3(CC5=CN(CCOCCOCCCCCCCl)N=N5)CC(=O)NC",
                                    msas=boltz_apo.output,
                                    affinity=True))
    boltz_holo_RR = pipeline.add(Boltz2(proteins=unique_new_sequences.output,
                                    ligands=r"CC/1(C)C2=C(C=CC=C2)N(C)\C1=C\C=C\C=C\C=C\[C@]34[C@](CC5=CN(CCOCCOCCCCCCCl)N=N5)(CC(=O)N3C)C6=C(C=CC=C6)N4C",
                                    msas=boltz_apo.output,
                                    affinity=True))
    boltz_holo_S = pipeline.add(Boltz2(proteins=unique_new_sequences.output,
                                    ligands=r"CC/1(C)C2=C(C=CC=C2)N(C)\C1=C\C=C\C=C\C=C\C3=[N+](C)C4=C(C=CC=C4)[C@]3(CC5=CN(CCOCCOCCCCCCCl)N=N5)CC(=O)NC",
                                    msas=boltz_apo.output,
                                    affinity=True))
    boltz_holo_SS = pipeline.add(Boltz2(proteins=unique_new_sequences.output,
                                    ligands=r"CC/1(C)C2=C(C=CC=C2)N(C)\C1=C\C=C\C=C\C=C\[C@@]34[C@@](CC5=CN(CCOCCOCCCCCCCl)N=N5)(CC(=O)N3C)C6=C(C=CC=C6)N4C",
                                    msas=boltz_apo.output,
                                    affinity=True))
    
    """
    Calculate distances and analysis 
    """
    R_chlorine_aspartate_distance = pipeline.add(ResidueAtomDistance(input=boltz_holo_R.output,
                                                                        residue='D in IHDWG',
                                                                        atom='LIG.Cl',
                                                                        metric_name='chlorine_distance'))
    S_chlorine_aspartate_distance = pipeline.add(ResidueAtomDistance(input=boltz_holo_S.output,
                                                                        residue='D in IHDWG',
                                                                        atom='LIG.Cl',
                                                                        metric_name='chlorine_distance'))
    R_cap_aspartate_distance = pipeline.add(ResidueAtomDistance(input=boltz_holo_R.output,
                                                                   residue='D in IHDWG',
                                                                   atom='LIG.N88',
                                                                   metric_name='cap_distance'))
    S_cap_aspartate_distance = pipeline.add(ResidueAtomDistance(input=boltz_holo_S.output,
                                                                   residue='D in IHDWG',
                                                                   atom='LIG.N88',
                                                                   metric_name='cap_distance'))
    
    ##analysis datasheets are merged 
    current_analysis = pipeline.add(MergeDatasheets(datasheets=[boltz_holo_R.output.datasheets.affinity,
                                                        boltz_holo_RR.output.datasheets.affinity,
                                                        boltz_holo_S.output.datasheets.affinity,
                                                        boltz_holo_SS.output.datasheets.affinity,
                                                        R_chlorine_aspartate_distance.output.datasheets.analysis,
                                                        S_chlorine_aspartate_distance.output.datasheets.analysis,
                                                        R_cap_aspartate_distance.output.datasheets.analysis,
                                                        S_cap_aspartate_distance.output.datasheets.analysis],
                                            prefixes=["R_","RR_","S_","SS_","R_","S_","R_","S_"],
                                            calculate = {
                                                "affinity_delta_R": "R_affinity_pred_value - RR_affinity_pred_value",
                                                "affinity_delta_S": "S_affinity_pred_value - SS_affinity_pred_value",
                                                "affinity_delta": "R_affinity_pred_value - RR_affinity_pred_value + S_affinity_pred_value - SS_affinity_pred_value",
                                                "affinity_open_sum": "R_affinity_pred_value + S_affinity_pred_value",
                                                "affinity_close_sum": "RR_affinity_pred_value + SS_affinity_pred_value"
                                                } ))
    current_filtered = pipeline.add(Filter(data=current_analysis.output,
                                    expression="R_chlorine_distance < 5.0 and S_chlorine_distance < 5.0 and R_cap_distance > 10.0 and S_cap_distance > 10.0"))
    
    # Add current cycle results to the arrays
    all_analyses.append(current_filtered)
    all_pools.append({"R":boltz_holo_R,"S":boltz_holo_S})
    
    """
    Select best across ALL cycles
    We select based on the same metric such that we end up with two proteins with the next sequence for the next round
    """
    best_R = pipeline.add(SelectBest(
        pool=[pool["R"].output for pool in all_pools],  # All pools from all cycles
        datasheets=[x.output.datasheets.merged for x in all_analyses],  # All analyses from all cycles
        metric='affinity_delta',
        mode='min',
        name=f'{CYCLE+1}_best'
    ))
    best_S = pipeline.add(SelectBest(
        pool=[pool["S"].output for pool in all_pools],  # All pools from all cycles
        datasheets=[x.output.datasheets.merged for x in all_analyses],  # All analyses from all cycles
        metric='affinity_delta',
        mode='min',
        name=f'{CYCLE+1}_best'
    ))
    all_open_best.append({"R":best_R,"S":best_S})


trajectories = {k: [all_analyses[0].output.datasheets.merged]+[x[k].output.datasheets.selected for x in all_open_best[1:]] for k in ["R","S"]}

pipeline.set_suffix("TRAJECTORIES")
pipeline.add(ConcatenateDatasheets(trajectories["R"])) #we only need R because all the data is there anyways

pipeline.set_suffix("ALL_ANALYSIS")
all_merged = [x.output.datasheets.merged for x in all_analyses]
pipeline.add(ConcatenateDatasheets(all_merged))
pipeline.add(AverageByDatasheet(all_merged))
for metric in ["affinity_delta",
               "affinity_delta_R",
               "affinity_delta_S",
               "R_affinity_pred_value",
               "S_affinity_pred_value",
               "RR_affinity_pred_value",
               "SS_affinity_pred_value"]:
    pipeline.set_suffix(metric)
    pipeline.add(ExtractMetric(datasheets=all_merged,
                            metric=metric))

#Prints
pipeline.save()
pipeline.slurm(email="") 
