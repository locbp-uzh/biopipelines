"""
This pipeline shows how improve the difference in predicted binding affinity between open and close form of a carbocyanine 7 chloride and halotag7 starting from a Boltz model of the open form.
We further introduce:
1. Filtering based on the distance between the end cap of the carbocyanine (specifically its nitrogen atom) and the aspartate, to avoid cases in which both the dye and the linker are within the pocket. 
One can open the original pdb file with pymol and click on the atom of interest in atom mode, to see the atom name:
Example: You clicked /1_best//B/LIG`1/N88 -> (pk1)
2. Treatment of two enantiomers and composition of sequences from mutation profile of both
"""

import os, sys
sys.path.insert(0, os.getcwd()) #to see scripts in current folder

from PipelineScripts.pipeline import Pipeline
from PipelineScripts.load_output import LoadOutput
from PipelineScripts.ligand_mpnn import LigandMPNN
from PipelineScripts.mutation_profiler import MutationProfiler
from PipelineScripts.mutation_composer import MutationComposer
from PipelineScripts.boltz2 import Boltz2
from PipelineScripts.residue_atom_distance import ResidueAtomDistance
from PipelineScripts.merge_datasheets import MergeDatasheets
from PipelineScripts.concatenate_datasheets import ConcatenateDatasheets
from PipelineScripts.remove_duplicates import RemoveDuplicates
from PipelineScripts.filter import Filter
from PipelineScripts.select_best import SelectBest
from PipelineScripts.average_by_datasheet import AverageByDatasheet
from PipelineScripts.extract_metrics import ExtractMetrics

pipeline = Pipeline(
    pipeline_name="LigandMPNN-MutationComposer-Cycle", #Will create a folder in /shares/USER/<pipeline_name>
    job_name="HT7_Cy7_C_enantiomers_single_point", #Unique job folder in /shares/USER/<pipeline_name>/job_name_NNN
    job_description="Profiling of mutations occuring over 1000 sequences generated by LigandMPNN and composition of sequences based on it, cycling to improve difference in affinity between open and bound")

pipeline.resources(
    gpu="A100",
    time="24:00:00",
    memory="16GB"
)

best_R = pipeline.add(LoadOutput('/shares/locbp.chem.uzh/public/BioPipelines/Boltz/HT7_Cy7_C_R_001/ToolOutputs/1_Boltz2_output.json'))
best_RR = pipeline.add(LoadOutput('/shares/locbp.chem.uzh/public/BioPipelines/Boltz/HT7_Cy7_C_RR_001/ToolOutputs/1_Boltz2_output.json'))
best_S = pipeline.add(LoadOutput('/shares/locbp.chem.uzh/public/BioPipelines/Boltz/HT7_Cy7_C_S_001/ToolOutputs/1_Boltz2_output.json'))
best_SS = pipeline.add(LoadOutput('/shares/locbp.chem.uzh/public/BioPipelines/Boltz/HT7_Cy7_C_SS_001/ToolOutputs/1_Boltz2_output.json'))

original_analysis = pipeline.add(MergeDatasheets(
    datasheets=[best_R.datasheets.affinity,
               best_RR.datasheets.affinity,
               best_S.datasheets.affinity,
               best_SS.datasheets.affinity],
    prefixes=["R_", "RR_","S_","SS_"],
    id_map={"original":["HT7_Cy7_C_R","HT7_Cy7_C_RR","HT7_Cy7_C_S","HT7_Cy7_C_SS"]},
    calculate={"affinity_delta_R": "R_affinity_pred_value - RR_affinity_pred_value",
               "affinity_delta_S": "S_affinity_pred_value - SS_affinity_pred_value",
               "affinity_delta": "R_affinity_pred_value - RR_affinity_pred_value + S_affinity_pred_value - SS_affinity_pred_value"}
))

NUM_CYCLES = 20
all_sequences_seen = None  # Track all sequences across cycles

# Track all analyses and pools across cycles for SelectBest
all_analyses = [original_analysis]  # Start with original baseline
all_pools = [{"R":best_R,"S":best_S}]  # Start with original best structure
all_open_best = [{"R":best_R,"S":best_S}] #will be used to plot the cycle-evolution 

for CYCLE in range(NUM_CYCLES):
    pipeline.set_suffix(f"Cycle{CYCLE}")

    mutation_range = "141+143+145+147-149+151-152+154+157+160-161+165+167-168+170-172+175-176+178+180+245+271"
    lmpnn_R = pipeline.add(LigandMPNN(structures=best_R, #this is equivalent to boltz2
                                    ligand="LIG", #in ligand mpnn you should always specify the ligand name, which is LIG if from Boltz
                                    num_sequences=1000,
                                    batch_size=25, 
                                    redesigned=mutation_range, 
                                    design_within=4))
    lmpnn_S = pipeline.add(LigandMPNN(structures=best_S, #this is equivalent to boltz2
                                    ligand="LIG", #in ligand mpnn you should always specify the ligand name, which is LIG if from Boltz
                                    num_sequences=1000,
                                    batch_size=25, 
                                    redesigned=mutation_range,
                                    design_within=4))
    
    profiler_R = pipeline.add(MutationProfiler(original=best_R,
                                             mutants=lmpnn_R))
    profiler_S = pipeline.add(MutationProfiler(original=best_S,
                                             mutants=lmpnn_S))
    ### Here we generate sequencies based on both tables of frequencies ###
    composer = pipeline.add(MutationComposer(frequencies=[profiler_R.datasheets.absolute_frequencies,
                                                          profiler_S.datasheets.absolute_frequencies],
                                             num_sequences=12,
                                             mode="single_point",
                                             combination_strategy="round_robin", #take one mutation from R one from S together
                                             prefix=f"HT_C{CYCLE+1}"))
    
    unique_new_sequences = pipeline.add(RemoveDuplicates(
        pool=composer,           
        history=all_sequences_seen.datasheets.concatenated if all_sequences_seen else None,  # History from previous cycles (None for first cycle)
        compare="sequence"          
    ))
    if all_sequences_seen is None:
        all_sequences_seen = pipeline.add(ConcatenateDatasheets(
            datasheets=[unique_new_sequences.datasheets.sequences]
        ))
    else:
        all_sequences_seen = pipeline.add(ConcatenateDatasheets(
            datasheets=[unique_new_sequences.datasheets.sequences, 
                       all_sequences_seen.datasheets.concatenated]
        ))
    
    boltz_apo = pipeline.add(Boltz2(proteins=unique_new_sequences))
    boltz_holo_R = pipeline.add(Boltz2(proteins=unique_new_sequences,
                                    ligands=best_R,
                                    msas=boltz_apo,
                                    affinity=True))
    boltz_holo_RR = pipeline.add(Boltz2(proteins=unique_new_sequences,
                                    ligands=best_R,
                                    msas=boltz_apo,
                                    affinity=True))
    boltz_holo_S = pipeline.add(Boltz2(proteins=unique_new_sequences,
                                    ligands=best_S,
                                    msas=boltz_apo,
                                    affinity=True))
    boltz_holo_SS = pipeline.add(Boltz2(proteins=unique_new_sequences,
                                    ligands=best_SS,
                                    msas=boltz_apo,
                                    affinity=True))
    
    R_chlorine_aspartate_distance = pipeline.add(ResidueAtomDistance(input=boltz_holo_R,
                                                                        residue='D in IHDWG',
                                                                        atom='LIG.Cl',
                                                                        metric_name='chlorine_distance'))
    S_chlorine_aspartate_distance = pipeline.add(ResidueAtomDistance(input=boltz_holo_S,
                                                                        residue='D in IHDWG',
                                                                        atom='LIG.Cl',
                                                                        metric_name='chlorine_distance'))
    R_cap_aspartate_distance = pipeline.add(ResidueAtomDistance(input=boltz_holo_R,
                                                                   residue='D in IHDWG',
                                                                   atom='LIG.N88',
                                                                   metric_name='cap_distance'))
    S_cap_aspartate_distance = pipeline.add(ResidueAtomDistance(input=boltz_holo_S,
                                                                   residue='D in IHDWG',
                                                                   atom='LIG.N88',
                                                                   metric_name='cap_distance'))
    
    ##analysis datasheets are merged 
    current_analysis = pipeline.add(MergeDatasheets(datasheets=[boltz_holo_R.datasheets.affinity,
                                                        boltz_holo_RR.datasheets.affinity,
                                                        boltz_holo_S.datasheets.affinity,
                                                        boltz_holo_SS.datasheets.affinity,
                                                        R_chlorine_aspartate_distance.datasheets.analysis,
                                                        S_chlorine_aspartate_distance.datasheets.analysis,
                                                        R_cap_aspartate_distance.datasheets.analysis,
                                                        S_cap_aspartate_distance.datasheets.analysis],
                                            prefixes=["R_","RR_","S_","SS_","R_","S_","R_","S_"],
                                            calculate = {
                                                "affinity_delta_R": "R_affinity_pred_value - RR_affinity_pred_value",
                                                "affinity_delta_S": "S_affinity_pred_value - SS_affinity_pred_value",
                                                "affinity_delta": "R_affinity_pred_value - RR_affinity_pred_value + S_affinity_pred_value - SS_affinity_pred_value",
                                                "affinity_open_sum": "R_affinity_pred_value + S_affinity_pred_value",
                                                "affinity_close_sum": "RR_affinity_pred_value + SS_affinity_pred_value"
                                                } ))
    current_filtered = pipeline.add(Filter(data=current_analysis,
                                    expression="R_chlorine_distance < 5.0 and S_chlorine_distance < 5.0 and R_cap_distance > 10.0 and S_cap_distance > 10.0"))
    
    # Add current cycle results to the arrays
    all_analyses.append(current_filtered)
    all_pools.append({"R":boltz_holo_R,"S":boltz_holo_S})

    # We select based on the same metric such that we end up with two proteins with the next sequence for the next round
    best_R = pipeline.add(SelectBest(
        pool=[pool["R"] for pool in all_pools],  # All pools from all cycles
        datasheets=[x.datasheets.merged for x in all_analyses],  # All analyses from all cycles
        metric='affinity_open_sum',
        mode='min',
        name=f'{CYCLE+1}_best'
    ))
    best_S = pipeline.add(SelectBest(
        pool=[pool["S"] for pool in all_pools],  # All pools from all cycles
        datasheets=[x.datasheets.merged for x in all_analyses],  # All analyses from all cycles
        metric='affinity_open_sum',
        mode='min',
        name=f'{CYCLE+1}_best'
    ))
    all_open_best.append({"R":best_R,"S":best_S})


trajectories = {k: [all_analyses[0].datasheets.merged]+[x[k].datasheets.selected for x in all_open_best[1:]] for k in ["R","S"]}

pipeline.set_suffix("TRAJECTORIES")
pipeline.add(ConcatenateDatasheets(trajectories["R"])) #we only need R because all the data is there anyways

pipeline.set_suffix("ALL_ANALYSIS")
all_merged = [x.datasheets.merged for x in all_analyses]
pipeline.add(ConcatenateDatasheets(all_merged))
pipeline.add(AverageByDatasheet(all_merged))

#extract metrics for column analysis on Prism
metrics = ["affinity_delta",
           "affinity_delta_R",
           "affinity_delta_S",
           "affinity_open_sum",
           "affinity_close_sum",
           "R_affinity_pred_value",
           "S_affinity_pred_value",
           "RR_affinity_pred_value",
           "SS_affinity_pred_value"]
pipeline.add(ExtractMetrics(datasheets=all_merged,
                            metrics=metrics))
#Prints
pipeline.save()
pipeline.slurm() 
